#
# Vivian, 2025/12/12
# File: APL_finance_analysis.py
# Financial data analysis of PT Agung Podomoro Land (APL) company
#

import pandas as pd
import numpy as np
from scipy import stats
from scipy.stats import pearsonr
import matplotlib.pyplot as plt
import seaborn as sns
import statsmodels.api as sm
from statsmodels.formula.api import ols
from sklearn.preprocessing import StandardScaler

# load data
df = pd.read_csv("APL_FinancialReport.csv")
print(f'Dataset shape: {df.shape}')

num_cols = ["Stock_Price", "Sales_Revenue", "Net_Income", "Operating_Income", "Marketing_Expenses", "Total_Assets", "Total_Liabilities"]
for c in num_cols:
    if c in df.columns:
        df[c] = pd.to_numeric(df[c], errors='coerce')

# format into billions
def format_billions(x, places=2):
    if pd.isna(x):
        return "NaN"
    return f"{x:.{places}f}B"

# Calculate summary statistics
summary = df[num_cols].describe().loc[["count", "mean", "std", "min", "max"]]

# Add missing value counts as a row
missing_row = df[num_cols].isna().sum()
summary.loc["missing"] = missing_row
# Outlier Detection 
z_scores = np.abs(stats.zscore(df[num_cols].dropna()))
outlier_mask = z_scores > 3
outlier_count_row = outlier_mask.any(axis=1).sum()
summary.loc["outliers"] = outlier_count_row
summary = summary.rename(index={"count": "N"})

# Display analytical summary
summary_display = summary.copy().astype(str)
for stat in ["mean", "std", "min", "max"]:
    summary_display.loc[stat] = summary_display.loc[stat].apply(lambda v: format_billions(float(v), 2) if v != 'nan' else "NaN")
print(" ")
print("=== Summary ===")
print(summary_display.T.to_string())

# Correlation matrix
print(" ")
print("=== Correlation Matrix ===")
correlation_matrix=df.iloc[:,1:8].corr()
print(correlation_matrix.round(3))


print(" ")
print("=== Correlation Significance Test===")
data_subset = df.iloc[:, 1:8]
correlation_matrix = data_subset.corr()

def calculate_pvalues(df_data):
    cols = df_data.columns
    p_values_matrix = pd.DataFrame(index=cols, columns=cols)
    
    for i in range(len(cols)):
        for j in range(len(cols)):
            _, p_value = pearsonr(df_data[cols[i]], df_data[cols[j]])
            p_values_matrix.iloc[i, j] = p_value
            
    return p_values_matrix.astype(float) 

p_values_matrix = calculate_pvalues(data_subset)
print(p_values_matrix.round(3))

sns.heatmap (correlation_matrix, annot=True, fmt=".2f", cmap='coolwarm')
plt.title ('Correlation Matrix')
plt.tight_layout()
plt.show()

# Stock price trend 
plt.plot(df['Year'], df['Stock_Price'], marker='o', linestyle='-', color='green')
plt.title('Stock Price Trend by Year', fontsize=16)
plt.xlabel('Year', fontsize=14)
plt.ylabel('Stock Price (Value)', fontsize=14)
plt.grid(True, linestyle='--', alpha=0.7) 
plt.xticks(df['Year']) 
plt.tight_layout()
plt.show()

# Assumption check
X_var = df['Marketing_Expenses']
y_var = df['Stock_Price']
X = sm.add_constant(X_var) 
model = sm.OLS(y_var, X).fit()

shapiro_p = stats.shapiro(model.resid).pvalue
bp_test = sm.stats.diagnostic.het_breuschpagan(model.resid, X)[3]

print(" ")
print("=== Regression Assumption Check Results ===")
assumption_results = pd.Series({
    "Shapiro-Wilk P-value (Normality)": round(shapiro_p, 3), 
    "Breusch-Pagan P-value (Homoscedasticity)": round(bp_test, 3)
})
print(assumption_results)

# Regression Analysis (Scatterplot)
x=df['Stock_Price']
y=df['Marketing_Expenses']
slope, intercept, r, p, std_err = stats.linregress(x,y)
def myfunc(x):
  return slope * x + intercept
mymodel = list(map(myfunc, x))
plt.title ('Linear Regression: Stock Price vs Marketing Expenses')
plt.scatter(x,y)
plt.plot(x, mymodel)
plt.xlabel('Stock_Price')
plt.ylabel('Marketing_Expenses')
plt.show()

model_formula = ('Stock_Price ~ Marketing_Expenses')
model = ols(model_formula, data=df).fit()
print(" ")
print(" === Regression Results Summary ===")
print(model.summary())



